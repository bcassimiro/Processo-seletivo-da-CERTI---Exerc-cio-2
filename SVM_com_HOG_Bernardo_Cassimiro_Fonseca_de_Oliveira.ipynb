{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM com HOG - Bernardo Cassimiro Fonseca de Oliveira.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIVUg7iNXf-m",
        "colab_type": "text"
      },
      "source": [
        "# Classificador de imagens \"*Thumbs Up*\" e \"*Thumbs Down*\"\n",
        "Autor: Bernardo Cassimiro Fonseca de Oliveira\n",
        "\n",
        "Essa ferramenta classifica imagens com \"*Thumbs Up*\" e \"*Thumbs Down*\" utilizando uma [Máquina de Vetor Suporte](https://scikit-learn.org/stable/modules/svm.html) (SVM, do inglês *Support Vector Machine*) com pré-processamento usando uma [Histograma de Gradientes](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_hog.html) (HOG, do inglês *Histogram of Gradients*).\n",
        "\n",
        "O *dataset* utilizado para o treinamento desse classificador foi criado por mim mesmo, filmando minhas mãos em diferentes ângulos com o celular. Os *frames* desses vídeos foram extraídos, gerando 1400 imagens para o treinamento e 800 imagens para teste. Além disso, 51 imagens retiradas da internet foram utilizadas para testar a capacidade de extrapolação do classificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGaxJ317XShL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: latin-1 -*-\n",
        "\n",
        "# Importando bibliotecas -------------------------------------------------------\n",
        "import cv2                        # Importa a OpenCV\n",
        "import numpy as np                # Importa a NumPy\n",
        "import os                         # Importa a Operational System\n",
        "from sklearn import svm           # Importa a SVM da Scikit Learn\n",
        "from skimage.feature import hog   # Importa o HOG da Scikit Image\n",
        "from skimage import exposure      # Importa a Exposure da Scikit Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwhtENpofSGQ",
        "colab_type": "text"
      },
      "source": [
        "**Carregamento das imagens**\n",
        "\n",
        "Nesta seção, as imagens são carregadas, seu HOG é calculado, linearizado e armazenado em *arrays* que serão utilizadas no treinamento, teste e extrapolação da SVM.\n",
        "\n",
        "O HOG foi aplicado nesse situação pois como o *dataset* de treino tem pouca variabilidade. Sem o HOG, a extrapolação teria um resultado ruim, pois o classificador jamais teria visto imagens similares. Com o HOG, um padrão no histogram emerge na presença de um \"*Thumbs Up*\" e de um \"*Thumbs Down*\", permitindo que, mesmo com imagens nunca vista, o classificador ainda consiga identificar o que precisa.\n",
        "\n",
        "Os parâmetros do HOG foram ajustados para serem plausíveis considerando o tamanho da imagem de treino, cuja resolução espacial é igual a (32 x 24) pixels. É possível que o resultado da classificação pudesse ser ainda melhor ao se testar diferentes parâmetros, utilizando por exemplo uma estrutura como uma *random search* ou uma *grid search*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LcBl8fgcoSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lendo as imagens de treinamento ----------------------------------------------\n",
        "dirTRAINING = 'training'                                                        # Seta a pasta em que estão as imagens para o treinamento\n",
        "listTRAINING = os.listdir(dirTRAINING)                                          # Lista a pasta em que estão as imagens para o treinamento\n",
        "numTRAINING = len(listTRAINING)                                                 # Obtém o número de imagens de treinamento\n",
        "\n",
        "training = np.zeros((numTRAINING,24*32)).astype(np.float64)                     # Inicializa um array 1400 x 768 de imagens linearizadas\n",
        "for img in range(1,numTRAINING):\n",
        "    imageNAME = ''.join([dirTRAINING,'\\\\',listTRAINING[img]])                   # Determina o endereço de cada imagem\n",
        "    image = cv2.imread(imageNAME,0)                                             # Abre a imagem em tons de cinza\n",
        "    _, hog_image = hog(image, orientations=18, pixels_per_cell=(4,4),           # Calcula o HOG da imagem\n",
        "                    cells_per_block=(1,1), visualize=True, multichannel=False)\n",
        "    image = exposure.rescale_intensity(hog_image, in_range=(0, 255))            # Impõe os limites da imagem do HOG entre 0 e 255 níveis de cinza\n",
        "    imageLINE = image.reshape(-1,24*32).astype(np.float64)                      # Lineariza a imagem\n",
        "    training[img,:] = imageLINE                                                 # Coloca a imagem linearizada no array de treinamento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COF07G1PepX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lendo as imagens de teste ----------------------------------------------------\n",
        "dirTEST = 'test'                                                                # Seta a pasta em que estão as imagens para o teste\n",
        "listTEST = os.listdir(dirTEST)                                                  # Lista a pasta em que estão as imagens para o teste\n",
        "numTEST = len(listTEST)                                                         # Obtém o número de imagens de teste\n",
        "    \n",
        "test = np.zeros((numTEST,24*32)).astype(np.float64)                             # Inicializa um array 800 x 768 de imagens linearizadas\n",
        "for img in range(1,numTEST):\n",
        "    imageNAME = ''.join([dirTEST,'\\\\',listTEST[img]])                           # Determina o endereço de cada imagem\n",
        "    image = cv2.imread(imageNAME,0)                                             # Abre a imagem em tons de cinza\n",
        "    _, hog_image = hog(image, orientations=18, pixels_per_cell=(4,4),           # Calcula o HOG da imagem\n",
        "                    cells_per_block=(1,1), visualize=True, multichannel=False)\n",
        "    image = exposure.rescale_intensity(hog_image, in_range=(0, 255))            # Impõe os limites da imagem do HOG entre 0 e 255 níveis de cinza \n",
        "    imageLINE = image.reshape(-1,24*32).astype(np.float64)                      # Lineariza a imagem\n",
        "    test[img,:] = imageLINE                                                     # Coloca a imagem linearizada no array de teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3ZBH0Y3f3v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lendo as imagens para a extrapolação -----------------------------------------\n",
        "dirGENERALIZATION = 'generalization'                                            # Seta a pasta em que estão as imagens para a extrapolação\n",
        "listGENERALIZATION = os.listdir(dirGENERALIZATION)                              # Lista a pasta em que estão as imagens para a extrapolação\n",
        "numGENERALIZATION = len(listGENERALIZATION)                                     # Obtém o número de imagens da extrapolação\n",
        "\n",
        "generalization = np.zeros((numGENERALIZATION,24*32)).astype(np.float64)         # Inicializa um array 51 x 768 de imagens linearizadas\n",
        "for img in range(1,numGENERALIZATION):\n",
        "    imageNAME = ''.join([dirGENERALIZATION,'\\\\',listGENERALIZATION[img]])       # Determina o endereço de cada imagem\n",
        "    image = cv2.imread(imageNAME,0)                                             # Abre a imagem em tons de cinza\n",
        "    _, hog_image = hog(image, orientations=18, pixels_per_cell=(4,4),           # Calcula o HOG da imagem\n",
        "                    cells_per_block=(1,1), visualize=True, multichannel=False)\n",
        "    image = exposure.rescale_intensity(hog_image, in_range=(0, 255))            # Impõe os limites da imagem do HOG entre 0 e 255 níveis de cinza \n",
        "    imageLINE = image.reshape(-1,24*32).astype(np.float64)                      # Lineariza a imagem\n",
        "    generalization[img,:] = imageLINE                                           # Coloca a imagem linearizada no array da extrapolação"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7TR9IeLg9_0",
        "colab_type": "text"
      },
      "source": [
        "**Criação das *labels* dos *datasets***\n",
        "\n",
        "Nesta seção, são criadas as *labels* dos *datasets*. Por conveniência, os *datasets* de treinamento e do teste foram organizados de forma que todas as imagens *Thumbs Up* vem primeiro no array depois vem todas as imagens *Thumbs Down*. Apenas o *dataset* da extrapolação tem uma ordem diferenciada.\n",
        "\n",
        "A *label* \"1\" identifica um \"*Thumbs Up*\" e a *label* \"0\" identifica um \"*Thumbs Down*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bqBonWhiDPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criando as labels ------------------------------------------------------------\n",
        "# trainingCSV = 'trainingLABELS.csv'\n",
        "# trainingLABELS = np.genfromtxt(trainingCSV, delimiter = '')\n",
        "trainingLABELS = np.concatenate((np.ones(int(numTRAINING/2)),                   # Gera um array de labels para o treinamento\n",
        "                                 np.zeros(int(numTRAINING/2))))\n",
        "\n",
        "# testCSV = 'testLABELS.csv'\n",
        "# testLABELS = np.genfromtxt(testCSV, delimiter = '')\n",
        "testLABELS = np.concatenate((np.ones(int(numTEST/2)),                           # Gera um array de labels para o teste\n",
        "                             np.zeros(int(numTEST/2))))\n",
        "\n",
        "# generalizationCSV = 'generalizationLABELS.csv'\n",
        "# generalizationLABELS = np.genfromtxt(generalizationCSV, delimiter = '') \n",
        "generalizationLABELS = np.array([0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,    # Gera um array de labels para a extrapolação\n",
        "                                 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
        "                                 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
        "                                 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
        "                                 1., 1., 1., 1., 0., 1., 1.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phAa_mRN1O0y",
        "colab_type": "text"
      },
      "source": [
        "**Treinamento da SVM**\n",
        "\n",
        "Nesta seção, é realizado o treinamento da SVM, utilizando os parâmetros padrão da ferramenta. Também não foram testados aqui diferentes parâmetros, de forma ser possível que o resultado da classificação possa ainda ser aprimorado.\n",
        "\n",
        "A SVM foi escolhida para essa classificação por ser uma ferramenta bastante conhecida, capaz de prover bons resultados de classificação, e que não exige um grande *dataset* para o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OZw8o1-2Lgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treinando a SVM --------------------------------------------------------------\n",
        "clf = svm.SVC()                     # Inicializa a ferramenta\n",
        "clf.fit(training, trainingLABELS)   # Realiza o treinamento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4a8s5FM3R4j",
        "colab_type": "text"
      },
      "source": [
        "**Verificação da performance da ferramenta com as imagens de teste e de extrapolação**\n",
        "\n",
        "Por fim, a performance do classificador é avaliado num conjunto de teste e num de extrapolação utilizadno a acurácia como métrica. Outras métricas podem ser utilizadas para avaliar diferentes aspectos do desempenho da ferramenta, como o recall, o F-score e o coeficiente de correlação de Matthews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdJpgDeg4ARR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificando a acurácia do teste ----------------------------------------------\n",
        "result = clf.predict(test)\n",
        "\n",
        "matches = result == testLABELS\n",
        "correct = np.count_nonzero(matches)\n",
        "accuracy = correct*100.0/len(result)\n",
        "print(accuracy)\n",
        "\n",
        "# Verificando a acurácia da generalização --------------------------------------\n",
        "resultGEN = clf.predict(generalization)\n",
        "\n",
        "matchesGEN = resultGEN == generalizationLABELS\n",
        "correctGEN = np.count_nonzero(matchesGEN)\n",
        "accuracyGEN = correctGEN*100.0/len(resultGEN)\n",
        "print(accuracyGEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxbt4AOl47yM",
        "colab_type": "text"
      },
      "source": [
        "Vê-se que a acurácia no conjunto de teste, com imagens similares às que foram usadas no treinamento, foi de {{accuracy}} %. O resultado foi bastante bom, mas que também pode indicar um overfitting da ferramenta.\n",
        "\n",
        "Como a acurácia no conjunto de extrapolação, com imagens bem diferentes em relação às que foram usadas no treinamento, foi de {{accuracyGEN}} %, pode se dizer que o classificador é capaz de generalizar, pois o resultado também foi alto, apesar de um pouco menor que o de teste.\n",
        "\n",
        "Conforme abordado anteriormente, o resultado da classificação pode vir a ser aprimorado ao se testar sistematicamente outros parâmetros do HOG e da SVM, bem como ao adicionar outras ferramentas de pré-processamento como a binzarização das imagens com a [segmentação de Otsu](https://ieeexplore.ieee.org/document/4310076) ou até mesmo a aplicação de outra ferramenta inteligente como a segmentação de instância com uma [Mask R-CNN](https://arxiv.org/abs/1703.06870) ou uma [Unet](https://arxiv.org/abs/1505.04597). "
      ]
    }
  ]
}